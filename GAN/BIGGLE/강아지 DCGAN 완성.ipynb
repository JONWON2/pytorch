{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from IPython import display\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision.utils as vutils\n",
    "from torch import optim\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "src = \"dog/Biggle\" #pokeRGB_black\n",
    "dst = \"resizedData/Biggle\" # resized\n",
    "\n",
    "\n",
    "os.mkdir(dst)\n",
    "\n",
    "for each in os.listdir(src):\n",
    "    img = cv2.imread(os.path.join(src,each))\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    cv2.imwrite(os.path.join(dst,each), img)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'newresizedData/'\n",
    "nz = 100 # 노이즈 벡터의 크기\n",
    "nc = 3 # 채널의 수\n",
    "ngf = 64 # generator 필터 조정\n",
    "ndf = 64 # discriminator 필터 조정\n",
    "epochNum = 2000 # 에폭 수\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "imageSize = 64 # 만들어지는 이미지의 크기\n",
    "batchSize = 1 # 미니배치의 크기\n",
    "outf = \"making/fake\"\n",
    "outf1 = \"making/real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class poketmon(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes   = os.listdir(path)\n",
    "        self.path      = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*.jpg\") for x in self.path]\n",
    "        self.transform = transform\n",
    "        files = []\n",
    "        print(self.transform)\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "        self.file_list = files\n",
    "       \n",
    "        \n",
    "        files = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "        return im, classCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5, 0.5, 0.5]\n",
    "std  = [0.5, 0.5, 0.5]\n",
    "transform = transforms.Compose([\n",
    "                                #transforms.Resize((160,160)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = poketmon(dir_path,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000000000542DA58>\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset,\n",
    "                         shuffle = True,\n",
    "                         batch_size = batchSize)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:         # Conv weight init\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            # 입력값은 Z이며 Transposed Convolution을 거칩니다.\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf * 8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf * 4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # (ngf * 2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # ngf x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # (nc) x 64 x 64)\n",
    "            nn.Conv2d(nc, ndf, 4,2,1,bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # ndf x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # (ndf * 2) x 16 x 16\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # (ndf * 4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG().cuda()\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "\n",
    "netD = _netD().cuda()\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "fixed_noise = Variable(fixed_noise).cuda()\n",
    "\n",
    "label = torch.FloatTensor(batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "199\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "299\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "399\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n",
      "99 step\n",
      "199 step\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochNum):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, _ = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "\n",
    "        inputv = Variable(input).cuda()\n",
    "        labelv = Variable(label).cuda()\n",
    "\n",
    "        output = netD(inputv)\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise).cuda()\n",
    "        fake = netG(noisev)\n",
    "        labelv = Variable(label.fill_(fake_label)).cuda()\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        netG.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label)).cuda()\n",
    "        output = netD(fake)\n",
    "\n",
    "        errG = criterion(output, labelv)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "        if ((i+1) % 100 == 0):\n",
    "            print(i, \"step\")\n",
    "            fake = netG(fixed_noise)\n",
    "            \n",
    "            vutils.save_image(fake.data,'%s/fake_samples_epoch_%s.png' % (outf, str(epoch)+\" \"+str(i+1)),normalize=True)\n",
    "            \n",
    "    vutils.save_image(real_cpu,'%s/real_samples.png' % outf1,normalize=True)\n",
    "    \n",
    "    fake = netG(fixed_noise)\n",
    "    \n",
    "    vutils.save_image(fake.data,'%s/fake_samples_epoch_%s.png' % (outf, epoch),normalize=True)\n",
    "    \n",
    "    result_dict = {\"loss_D\":errD,\"errD_fake\":errD_fake }\n",
    "    if (epoch+1) % 100 ==0:\n",
    "        print(epoch)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG.pth' % (outf))\n",
    "    torch.save(netD.state_dict(), '%s/netD.pth' % (outf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
